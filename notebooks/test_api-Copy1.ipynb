{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b7c0c4",
   "metadata": {},
   "source": [
    "# Envoi d'une requête POST à l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433ad00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'predictions': [1, 1, 1, 1, 0, 1, 1, 1, 1, 1], 'probabilities': [[0.11382782459259033, 0.8861721754074097], [0.035747408866882324, 0.9642525911331177], [0.09581917524337769, 0.9041808247566223], [0.3050164580345154, 0.6949835419654846], [0.5528578758239746, 0.4471421241760254], [0.19616049528121948, 0.8038395047187805], [0.028150558471679688, 0.9718494415283203], [0.2058795690536499, 0.7941204309463501], [0.3100093603134155, 0.6899906396865845], [0.06641316413879395, 0.933586835861206]]}\n",
      "Somme des probabilités pour l'instance 0: 1.0\n",
      "Somme des probabilités pour l'instance 1: 1.0\n",
      "Somme des probabilités pour l'instance 2: 1.0\n",
      "Somme des probabilités pour l'instance 3: 1.0\n",
      "Somme des probabilités pour l'instance 4: 1.0\n",
      "Somme des probabilités pour l'instance 5: 1.0\n",
      "Somme des probabilités pour l'instance 6: 1.0\n",
      "Somme des probabilités pour l'instance 7: 1.0\n",
      "Somme des probabilités pour l'instance 8: 1.0\n",
      "Somme des probabilités pour l'instance 9: 1.0\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le preprocessor\n",
    "path_preprocessor = '../models/preprocessor.joblib'\n",
    "preprocessor = load(path_preprocessor)\n",
    "\n",
    "# Charger les noms des caractéristiques\n",
    "with open(\"../models/feature_names.txt\", \"r\") as f:\n",
    "    feature_names = f.read().splitlines()\n",
    "\n",
    "# Charger les données de test\n",
    "data_test = pd.read_csv(\"../data/processed/processed_data_test_sample.csv\")\n",
    "\n",
    "# Exclure les colonnes inutiles\n",
    "data_test = data_test.loc[:, ~data_test.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Réorganiser les colonnes pour qu'elles correspondent à celles utilisées lors de l'entraînement\n",
    "data_test = data_test[feature_names]\n",
    "\n",
    "# Appliquer le pipeline de prétraitement\n",
    "data_test_preprocessed = preprocessor.transform(data_test)\n",
    "\n",
    "# Convertir les données en dictionnaire avant l'envoi\n",
    "data_dict = pd.DataFrame(data_test_preprocessed, columns=feature_names).to_dict(orient='records')\n",
    "\n",
    "# URL de l'API locale\n",
    "url = \"http://127.0.0.1:5000/predict\"\n",
    "\n",
    "# Envoyer la requête POST\n",
    "response = requests.post(url, json=data_dict)\n",
    "\n",
    "# Afficher la réponse\n",
    "print(\"Response:\", response.json())\n",
    "\n",
    "# Vérifier que les probabilités s'additionnent à 1 pour chaque instance\n",
    "probabilities = response.json()['probabilities']\n",
    "for i, prob in enumerate(probabilities):\n",
    "    print(f\"Somme des probabilités pour l'instance {i}: {sum(prob)}\")\n",
    "    assert abs(sum(prob) - 1.0) < 1e-6, f\"Les probabilités ne s'additionnent pas à 1 pour l'instance {i}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853b653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
